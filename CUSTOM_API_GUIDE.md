# è‡ªå®šä¹‰ API ä½¿ç”¨æŒ‡å— / Custom API Guide

[ä¸­æ–‡](#ä¸­æ–‡) | [English](#english)

---

## ä¸­æ–‡

### åŠŸèƒ½æ¦‚è¿°

NotOnlyTranslator ç°åœ¨æ”¯æŒè‡ªå®šä¹‰ API ç«¯ç‚¹ï¼Œæ‚¨å¯ä»¥ï¼š

1. **ä½¿ç”¨è‡ªå®šä¹‰ LLM æœåŠ¡**ï¼šè¿æ¥åˆ°ä»»ä½•å…¼å®¹ OpenAI æ ¼å¼çš„ API
2. **è¦†ç›–é»˜è®¤ç«¯ç‚¹**ï¼šä¸º OpenAI/Anthropic ä½¿ç”¨è‡ªå®šä¹‰ URLï¼ˆå¦‚ API ä»£ç†ï¼‰
3. **æŒ‡å®šæ¨¡å‹åç§°**ï¼šä½¿ç”¨ç‰¹å®šçš„æ¨¡å‹ç‰ˆæœ¬

### ä½¿ç”¨åœºæ™¯

- ğŸ  **æœ¬åœ°éƒ¨ç½²æ¨¡å‹**ï¼šå¦‚ LM Studioã€Ollamaã€vLLM
- ğŸŒ **ç¬¬ä¸‰æ–¹APIæœåŠ¡**ï¼šå¦‚å›½å†…çš„ API æœåŠ¡å•†
- ğŸš€ **API ä»£ç†**ï¼šé€šè¿‡ä»£ç†è®¿é—® OpenAI/Anthropic
- ğŸ”§ **è‡ªå»ºæœåŠ¡**ï¼šè‡ªå·±æ­å»ºçš„ LLM æœåŠ¡

### é…ç½®æ­¥éª¤

#### 1. æ‰“å¼€è®¾ç½®é¡µé¢
ç‚¹å‡»æ’ä»¶å›¾æ ‡ â†’ è®¾ç½®å›¾æ ‡ â†’ API è®¾ç½®

#### 2. é€‰æ‹© API ç±»å‹

**é€‰é¡¹ A - è‡ªå®šä¹‰ API**ï¼š
1. é€‰æ‹©"è‡ªå®šä¹‰ API"
2. è¾“å…¥ API ç«¯ç‚¹ URL
3. è¾“å…¥æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
4. è¾“å…¥ API å¯†é’¥
5. ç‚¹å‡»"æµ‹è¯•å¯†é’¥"éªŒè¯è¿æ¥
6. ç‚¹å‡»"ä¿å­˜è®¾ç½®"

**é€‰é¡¹ B - è¦†ç›–é»˜è®¤ API**ï¼š
1. é€‰æ‹© OpenAI æˆ– Anthropic
2. ç‚¹å‡»"+ è‡ªå®šä¹‰ API ç«¯ç‚¹"
3. è¾“å…¥è‡ªå®šä¹‰ URL
4. ï¼ˆå¯é€‰ï¼‰ä¿®æ”¹æ¨¡å‹åç§°
5. è¾“å…¥ API å¯†é’¥
6. æµ‹è¯•å¹¶ä¿å­˜

### API æ ¼å¼è¦æ±‚

è‡ªå®šä¹‰ API å¿…é¡»å…¼å®¹ OpenAI çš„è¯·æ±‚/å“åº”æ ¼å¼ï¼š

#### è¯·æ±‚æ ¼å¼
```json
{
  "model": "your-model-name",
  "messages": [
    {
      "role": "system",
      "content": "You are an English learning assistant..."
    },
    {
      "role": "user",
      "content": "è¯·æ±‚å†…å®¹..."
    }
  ],
  "temperature": 0.3,
  "response_format": { "type": "json_object" }
}
```

#### å“åº”æ ¼å¼
```json
{
  "choices": [
    {
      "message": {
        "content": "å“åº”å†…å®¹..."
      }
    }
  ]
}
```

æˆ–è€… Anthropic æ ¼å¼ï¼š
```json
{
  "content": [
    {
      "text": "å“åº”å†…å®¹..."
    }
  ]
}
```

### å¸¸è§é…ç½®ç¤ºä¾‹

#### LM Studioï¼ˆæœ¬åœ°ï¼‰
```
API URL: http://localhost:1234/v1/chat/completions
æ¨¡å‹åç§°: local-model
API Key: ä»»æ„å­—ç¬¦ä¸²ï¼ˆLM Studio ä¸éªŒè¯ï¼‰
```

#### Ollamaï¼ˆæœ¬åœ°ï¼‰
éœ€è¦ä½¿ç”¨ Ollama çš„ OpenAI å…¼å®¹å±‚ï¼š
```
API URL: http://localhost:11434/v1/chat/completions
æ¨¡å‹åç§°: llama2
API Key: ollama
```

#### OpenAI ä»£ç†
```
API URL: https://your-proxy.com/v1/chat/completions
æ¨¡å‹åç§°: gpt-4o-miniï¼ˆæˆ–å…¶ä»–ï¼‰
API Key: æ‚¨çš„ OpenAI API å¯†é’¥
```

### æƒé™è¯´æ˜

ä½¿ç”¨è‡ªå®šä¹‰ API æ—¶ï¼Œæµè§ˆå™¨å¯èƒ½ä¼šæç¤ºæˆäºˆé¢å¤–çš„ç½‘ç»œè®¿é—®æƒé™ã€‚è¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæ‰©å±•éœ€è¦è®¿é—®æ‚¨æŒ‡å®šçš„è‡ªå®šä¹‰åŸŸåã€‚

æ‚¨å¯ä»¥ï¼š
- ç‚¹å‡»å…è®¸ä»¥ä½¿ç”¨è¯¥åŸŸå
- æˆ–åœ¨ `chrome://extensions/` ä¸­æ‰‹åŠ¨ç®¡ç†æƒé™

### æ•…éšœæ’æŸ¥

#### è¿æ¥å¤±è´¥
1. æ£€æŸ¥ API URL æ˜¯å¦æ­£ç¡®
2. ç¡®è®¤æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œï¼ˆå¯¹äºæœ¬åœ°æœåŠ¡ï¼‰
3. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
4. æŸ¥çœ‹æµè§ˆå™¨æ§åˆ¶å°ï¼ˆF12ï¼‰çš„é”™è¯¯ä¿¡æ¯

#### å“åº”æ ¼å¼é”™è¯¯
1. ç¡®è®¤ API è¿”å›çš„æ ¼å¼å…¼å®¹ OpenAI
2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒ JSON è¾“å‡º
3. å°è¯•åœ¨ API æœåŠ¡å™¨ç«¯æ·»åŠ æ ¼å¼è½¬æ¢

#### ç¿»è¯‘è´¨é‡é—®é¢˜
1. å°è¯•ä¸åŒçš„æ¨¡å‹
2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒä¸­æ–‡
3. è°ƒæ•´æ¸©åº¦å‚æ•°ï¼ˆå¦‚æœ API æ”¯æŒï¼‰

### å®‰å…¨å»ºè®®

- âœ… æœ¬åœ°æ¨¡å‹ï¼šæœ€å®‰å…¨ï¼Œæ•°æ®ä¸ç¦»å¼€æœ¬åœ°
- âœ… è‡ªå»ºæœåŠ¡ï¼šéœ€è¦ç¡®ä¿æœåŠ¡å™¨å®‰å…¨
- âš ï¸ ç¬¬ä¸‰æ–¹æœåŠ¡ï¼šæ³¨æ„æ•°æ®éšç§æ”¿ç­–
- âš ï¸ å…¬å…±ä»£ç†ï¼šé¿å…ä½¿ç”¨ä¸å¯ä¿¡çš„ä»£ç†

---

## English

### Feature Overview

NotOnlyTranslator now supports custom API endpoints, allowing you to:

1. **Use custom LLM services**: Connect to any OpenAI-compatible API
2. **Override default endpoints**: Use custom URLs for OpenAI/Anthropic (e.g., API proxies)
3. **Specify model names**: Use specific model versions

### Use Cases

- ğŸ  **Local models**: LM Studio, Ollama, vLLM
- ğŸŒ **Third-party services**: Alternative API providers
- ğŸš€ **API proxies**: Access OpenAI/Anthropic through proxies
- ğŸ”§ **Self-hosted**: Your own LLM deployment

### Configuration Steps

#### 1. Open Settings
Click extension icon â†’ Settings icon â†’ API Settings

#### 2. Choose API Type

**Option A - Custom API**:
1. Select "Custom API"
2. Enter API endpoint URL
3. Enter model name (optional)
4. Enter API key
5. Click "Test Key" to verify
6. Click "Save Settings"

**Option B - Override Default**:
1. Select OpenAI or Anthropic
2. Click "+ Custom API Endpoint"
3. Enter custom URL
4. (Optional) Change model name
5. Enter API key
6. Test and save

### API Format Requirements

Custom APIs must be compatible with OpenAI's request/response format:

#### Request Format
```json
{
  "model": "your-model-name",
  "messages": [
    {
      "role": "system",
      "content": "You are an English learning assistant..."
    },
    {
      "role": "user",
      "content": "Request content..."
    }
  ],
  "temperature": 0.3,
  "response_format": { "type": "json_object" }
}
```

#### Response Format
```json
{
  "choices": [
    {
      "message": {
        "content": "Response content..."
      }
    }
  ]
}
```

Or Anthropic format:
```json
{
  "content": [
    {
      "text": "Response content..."
    }
  ]
}
```

### Configuration Examples

#### LM Studio (Local)
```
API URL: http://localhost:1234/v1/chat/completions
Model Name: local-model
API Key: any-string (LM Studio doesn't validate)
```

#### Ollama (Local)
Requires Ollama's OpenAI compatibility layer:
```
API URL: http://localhost:11434/v1/chat/completions
Model Name: llama2
API Key: ollama
```

#### OpenAI Proxy
```
API URL: https://your-proxy.com/v1/chat/completions
Model Name: gpt-4o-mini (or others)
API Key: Your OpenAI API key
```

### Permissions

When using custom APIs, the browser may prompt for additional network access permissions. This is normal as the extension needs to access your custom domain.

You can:
- Click allow to use that domain
- Or manually manage permissions in `chrome://extensions/`

### Troubleshooting

#### Connection Failed
1. Verify API URL is correct
2. Ensure service is running (for local services)
3. Check firewall settings
4. Check browser console (F12) for errors

#### Format Error
1. Confirm API returns OpenAI-compatible format
2. Check if model supports JSON output
3. Try adding format conversion on API server

#### Translation Quality Issues
1. Try different models
2. Check if model supports Chinese
3. Adjust temperature parameter (if supported)

### Security Tips

- âœ… Local models: Most secure, data stays local
- âœ… Self-hosted: Ensure server security
- âš ï¸ Third-party: Check privacy policy
- âš ï¸ Public proxies: Avoid untrusted proxies

---

## Support

å¦‚æœ‰é—®é¢˜ï¼Œè¯·è®¿é—®ï¼š
For support, visit:

- GitHub Issues: https://github.com/yourusername/notOnlyTranslator/issues
- Documentation: https://github.com/yourusername/notOnlyTranslator
